{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YdMCgrRTzNSY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization, Input,  MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4WqN0rzzoW0",
        "outputId": "8ff98629-b722-4327-f053-6105591ed8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2v3Jvky309G",
        "outputId": "7fa535df-c80d-4023-f288-cc29863a8ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Emotion\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dNP1LlVPzy_-"
      },
      "outputs": [],
      "source": [
        "# !unzip Emotion2.zip\n",
        "#la base de donnée contient 7 classes mais on a utilisé seulement 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqWzvD6Q0MuV",
        "outputId": "32b122fa-9b60-4cf9-fc48-016b8751cd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.h5  Emotion.zip  sad.jpg  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  vgg16_tfds.h5\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LRJ5Anou0Q0X"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_size = 48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LVxfRo9o0Y4P"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
        "                                         width_shift_range = 0.1,\n",
        "                                         height_shift_range = 0.1,\n",
        "                                         horizontal_flip = True,\n",
        "                                         rescale = 1./255,\n",
        "                                         #zoom_range = 0.2,\n",
        "                                         validation_split = 0.2\n",
        "                                        )\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                         validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er6LDkVR0h3e",
        "outputId": "5850d00b-0f39-40c9-d69d-bf1df46a7ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17010 images belonging to 3 classes.\n",
            "Found 4254 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JcujDnYr0qrW"
      },
      "outputs": [],
      "source": [
        "#l'architecture utilisé\n",
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JS7GerC12-7t"
      },
      "outputs": [],
      "source": [
        "epochs = 60\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYJDXSyS5wTw",
        "outputId": "23abb81e-0bb4-4435-aeba-a114a7884c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 44, 44, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 22, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,341,507\n",
            "Trainable params: 2,341,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "emotion_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ivcUacdwOzvk"
      },
      "outputs": [],
      "source": [
        "# Simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxfw-Zxgv2CM",
        "outputId": "05be1a33-ff64-4ed0-b9dc-7fbd27e85ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SyqpkHmO58X",
        "outputId": "d0ae156e-b1d0-445a-dbd1-3a8562093e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "265/265 [==============================] - 3159s 12s/step - loss: 1.0766 - accuracy: 0.4235 - val_loss: 1.0666 - val_accuracy: 0.4356\n",
            "Epoch 2/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 1.0308 - accuracy: 0.4740 - val_loss: 0.9526 - val_accuracy: 0.5597\n",
            "Epoch 3/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.8802 - val_accuracy: 0.5926\n",
            "Epoch 4/50\n",
            "265/265 [==============================] - 34s 128ms/step - loss: 0.9268 - accuracy: 0.5623 - val_loss: 0.8197 - val_accuracy: 0.6165\n",
            "Epoch 5/50\n",
            "265/265 [==============================] - 33s 126ms/step - loss: 0.8766 - accuracy: 0.5935 - val_loss: 0.7805 - val_accuracy: 0.6484\n",
            "Epoch 6/50\n",
            "265/265 [==============================] - 34s 128ms/step - loss: 0.8473 - accuracy: 0.6101 - val_loss: 0.7585 - val_accuracy: 0.6446\n",
            "Epoch 7/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.8080 - accuracy: 0.6276 - val_loss: 0.7434 - val_accuracy: 0.6560\n",
            "Epoch 8/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 0.7829 - accuracy: 0.6369 - val_loss: 0.7013 - val_accuracy: 0.6861\n",
            "Epoch 9/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.7632 - accuracy: 0.6474 - val_loss: 0.7012 - val_accuracy: 0.6792\n",
            "Epoch 10/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.7443 - accuracy: 0.6611 - val_loss: 0.6960 - val_accuracy: 0.6728\n",
            "Epoch 11/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.7306 - accuracy: 0.6643 - val_loss: 0.6692 - val_accuracy: 0.6972\n",
            "Epoch 12/50\n",
            "265/265 [==============================] - 33s 126ms/step - loss: 0.7148 - accuracy: 0.6766 - val_loss: 0.6467 - val_accuracy: 0.7053\n",
            "Epoch 13/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.6981 - accuracy: 0.6824 - val_loss: 0.6518 - val_accuracy: 0.7043\n",
            "Epoch 14/50\n",
            "265/265 [==============================] - 33s 126ms/step - loss: 0.6886 - accuracy: 0.6887 - val_loss: 0.6323 - val_accuracy: 0.7143\n",
            "Epoch 15/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.6833 - accuracy: 0.6908 - val_loss: 0.6277 - val_accuracy: 0.7173\n",
            "Epoch 16/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.6715 - accuracy: 0.7020 - val_loss: 0.6497 - val_accuracy: 0.7086\n",
            "Epoch 17/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.6650 - accuracy: 0.7021 - val_loss: 0.6159 - val_accuracy: 0.7285\n",
            "Epoch 18/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.6581 - accuracy: 0.7081 - val_loss: 0.6107 - val_accuracy: 0.7308\n",
            "Epoch 19/50\n",
            "265/265 [==============================] - 32s 123ms/step - loss: 0.6490 - accuracy: 0.7124 - val_loss: 0.6489 - val_accuracy: 0.7057\n",
            "Epoch 20/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.6380 - accuracy: 0.7206 - val_loss: 0.6280 - val_accuracy: 0.7221\n",
            "Epoch 21/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.6382 - accuracy: 0.7208 - val_loss: 0.5955 - val_accuracy: 0.7353\n",
            "Epoch 22/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.6282 - accuracy: 0.7268 - val_loss: 0.5900 - val_accuracy: 0.7464\n",
            "Epoch 23/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.6190 - accuracy: 0.7281 - val_loss: 0.5966 - val_accuracy: 0.7370\n",
            "Epoch 24/50\n",
            "265/265 [==============================] - 32s 122ms/step - loss: 0.6157 - accuracy: 0.7305 - val_loss: 0.5844 - val_accuracy: 0.7474\n",
            "Epoch 25/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.6087 - accuracy: 0.7293 - val_loss: 0.5849 - val_accuracy: 0.7457\n",
            "Epoch 26/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.6077 - accuracy: 0.7337 - val_loss: 0.6013 - val_accuracy: 0.7372\n",
            "Epoch 27/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.5964 - accuracy: 0.7396 - val_loss: 0.5933 - val_accuracy: 0.7353\n",
            "Epoch 28/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.5922 - accuracy: 0.7430 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 29/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.5934 - accuracy: 0.7444 - val_loss: 0.5976 - val_accuracy: 0.7341\n",
            "Epoch 30/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.5903 - accuracy: 0.7439 - val_loss: 0.5703 - val_accuracy: 0.7524\n",
            "Epoch 31/50\n",
            "265/265 [==============================] - 33s 125ms/step - loss: 0.5843 - accuracy: 0.7470 - val_loss: 0.5675 - val_accuracy: 0.7517\n",
            "Epoch 32/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.5806 - accuracy: 0.7440 - val_loss: 0.5603 - val_accuracy: 0.7576\n",
            "Epoch 33/50\n",
            "265/265 [==============================] - 33s 123ms/step - loss: 0.5804 - accuracy: 0.7491 - val_loss: 0.5667 - val_accuracy: 0.7491\n",
            "Epoch 34/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.5734 - accuracy: 0.7504 - val_loss: 0.5621 - val_accuracy: 0.7557\n",
            "Epoch 35/50\n",
            "265/265 [==============================] - 33s 124ms/step - loss: 0.5716 - accuracy: 0.7548 - val_loss: 0.5741 - val_accuracy: 0.7533\n",
            "Epoch 36/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 0.5689 - accuracy: 0.7541 - val_loss: 0.5591 - val_accuracy: 0.7602\n",
            "Epoch 37/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 0.5652 - accuracy: 0.7575 - val_loss: 0.5998 - val_accuracy: 0.7424\n",
            "Epoch 38/50\n",
            "265/265 [==============================] - 34s 128ms/step - loss: 0.5697 - accuracy: 0.7507 - val_loss: 0.5503 - val_accuracy: 0.7614\n",
            "Epoch 39/50\n",
            "265/265 [==============================] - 34s 129ms/step - loss: 0.5553 - accuracy: 0.7602 - val_loss: 0.5761 - val_accuracy: 0.7507\n",
            "Epoch 40/50\n",
            "265/265 [==============================] - 35s 131ms/step - loss: 0.5560 - accuracy: 0.7620 - val_loss: 0.5551 - val_accuracy: 0.7595\n",
            "Epoch 41/50\n",
            "265/265 [==============================] - 33s 126ms/step - loss: 0.5500 - accuracy: 0.7635 - val_loss: 0.5553 - val_accuracy: 0.7583\n",
            "Epoch 42/50\n",
            "265/265 [==============================] - 34s 127ms/step - loss: 0.5510 - accuracy: 0.7617 - val_loss: 0.5534 - val_accuracy: 0.7595\n",
            "Epoch 43/50\n",
            "265/265 [==============================] - 34s 128ms/step - loss: 0.5455 - accuracy: 0.7655 - val_loss: 0.5384 - val_accuracy: 0.7699\n",
            "Epoch 44/50\n",
            "265/265 [==============================] - 34s 129ms/step - loss: 0.5518 - accuracy: 0.7612 - val_loss: 0.5362 - val_accuracy: 0.7696\n",
            "Epoch 45/50\n",
            "265/265 [==============================] - 34s 128ms/step - loss: 0.5432 - accuracy: 0.7654 - val_loss: 0.5358 - val_accuracy: 0.7692\n",
            "Epoch 46/50\n",
            "265/265 [==============================] - 34s 129ms/step - loss: 0.5399 - accuracy: 0.7690 - val_loss: 0.5453 - val_accuracy: 0.7659\n",
            "Epoch 47/50\n",
            "265/265 [==============================] - 35s 133ms/step - loss: 0.5338 - accuracy: 0.7684 - val_loss: 0.5387 - val_accuracy: 0.7670\n",
            "Epoch 48/50\n",
            "265/265 [==============================] - 35s 132ms/step - loss: 0.5361 - accuracy: 0.7732 - val_loss: 0.5439 - val_accuracy: 0.7652\n",
            "Epoch 49/50\n",
            "265/265 [==============================] - 35s 130ms/step - loss: 0.5291 - accuracy: 0.7738 - val_loss: 0.5328 - val_accuracy: 0.7711\n",
            "Epoch 50/50\n",
            "265/265 [==============================] - 34s 129ms/step - loss: 0.5284 - accuracy: 0.7772 - val_loss: 0.5337 - val_accuracy: 0.7675\n"
          ]
        }
      ],
      "source": [
        "emotion_model_info = emotion_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=17010 // 64,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=4254 // 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kIJamBeLO6LM"
      },
      "outputs": [],
      "source": [
        "# save model structure in jason file\n",
        "model_json = emotion_model.to_json()\n",
        "with open(\"emotion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# save trained model weight in .h5 file\n",
        "emotion_model.save_weights('emotion_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rHK17q6v-hqN"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "emotion5.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}